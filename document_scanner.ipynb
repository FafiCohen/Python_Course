{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FafiCohen/Python_Course/blob/main/document_scanner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lInSjsGZgFT2",
        "outputId": "24bddb77-4e2c-45bb-d51a-3625081f294a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 0s (9,708 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 121749 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m655.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install -q streamlit\n",
        "!pip install -q  googletrans\n",
        "!pip install -q deep_translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZxFpHhRgLw5",
        "outputId": "061dd16a-aa12-42f8-db85-180da268a1f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import pytesseract\n",
        "from googletrans import Translator\n",
        "from deep_translator import GoogleTranslator\n",
        "from PIL import Image\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def apply_morphological_operation(image):\n",
        "    # Apply morphological operations (e.g., erosion, dilation)\n",
        "    morph_kernel = np.ones((5,5), np.uint8)\n",
        "    processed_image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, morph_kernel, iterations=4)\n",
        "    return processed_image\n",
        "\n",
        "def detect_edge_contours(image):\n",
        "    mask = np.zeros(image.shape[:2], np.uint8)\n",
        "    bgd_model = np.zeros((1,65), np.float64)\n",
        "    fgd_model = np.zeros((1,65), np.float64)\n",
        "    rect = (20, 20, image.shape[1]-20, image.shape[0]-20)\n",
        "    cv2.grabCut(image, mask, rect, bgd_model, fgd_model, 5, cv2.GC_INIT_WITH_RECT)\n",
        "    mask2 = np.where((mask==2) | (mask==0), 0, 1).astype('uint8')\n",
        "    image = image * mask2[:, :, np.newaxis]\n",
        "\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.GaussianBlur(gray, (11, 11), 0)\n",
        "    canny = cv2.Canny(gray, 0, 200)\n",
        "    canny = cv2.dilate(canny, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)))\n",
        "    contours, hierarchy = cv2.findContours(canny, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
        "    page = sorted(contours, key=cv2.contourArea, reverse=True)[:5]\n",
        "    con = np.zeros_like(image)\n",
        "    con = cv2.drawContours(con, page, -1, (100, 255, 100), 4)\n",
        "    return con, page\n",
        "\n",
        "def arrange_points(pts):\n",
        "    rect = np.zeros((4, 2), dtype='float32')\n",
        "    pts = np.array(pts)\n",
        "    s = pts.sum(axis=1)\n",
        "    rect[0] = pts[np.argmin(s)]\n",
        "    rect[2] = pts[np.argmax(s)]\n",
        "\n",
        "    diff = np.diff(pts, axis=1)\n",
        "    rect[1] = pts[np.argmin(diff)]\n",
        "    rect[3] = pts[np.argmax(diff)]\n",
        "    return rect.astype('int').tolist()\n",
        "\n",
        "def find_corner_points(image):\n",
        "    page = detect_edge_contours(image)[1]\n",
        "    con = np.zeros_like(image)\n",
        "    for c in page:\n",
        "        epsilon = 0.02 * cv2.arcLength(c, True)\n",
        "        corners = cv2.approxPolyDP(c, epsilon, True)\n",
        "        if len(corners) == 4:\n",
        "            break\n",
        "    cv2.drawContours(con, c, -1, (100, 255, 100), 4)\n",
        "    cv2.drawContours(con, corners, -1, (0, 255, 0), 10)\n",
        "    corners = sorted(np.concatenate(corners).tolist())\n",
        "    for index, c in enumerate(corners):\n",
        "        character = chr(65 + index)\n",
        "        cv2.putText(con, character, tuple(c), cv2.FONT_HERSHEY_SIMPLEX, 5, (255, 0, 0), 5, cv2.LINE_AA)\n",
        "    corners = arrange_points(corners)\n",
        "    return con, corners\n",
        "\n",
        "def find_destination(pts):\n",
        "    (tl, tr, br, bl) = pts\n",
        "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
        "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
        "    maxWidth = max(int(widthA), int(widthB))\n",
        "\n",
        "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
        "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
        "    maxHeight = max(int(heightA), int(heightB))\n",
        "    destination_corners = [[0, 0], [maxWidth, 0], [maxWidth, maxHeight], [0, maxHeight]]\n",
        "    return arrange_points(destination_corners)\n",
        "\n",
        "def apply_perspective_transform(image):\n",
        "    pts = find_corner_points(image)[1]\n",
        "    destination_corners = find_destination(pts)\n",
        "    M = cv2.getPerspectiveTransform(np.float32(pts), np.float32(destination_corners))\n",
        "    final = cv2.warpPerspective(image, M, (destination_corners[2][0], destination_corners[2][1]), flags=cv2.INTER_LINEAR)\n",
        "    return final\n",
        "\n",
        "\n",
        "def preprocess_image(image ):\n",
        "\n",
        "    gray = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply thresholding to binarize the image\n",
        "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "    return binary\n",
        "\n",
        "def perform_ocr_and_translate(image):\n",
        "    # Preprocess the image\n",
        "    preprocessed_image = preprocess_image(image)\n",
        "\n",
        "    # Perform OCR on the preprocessed image\n",
        "    text = pytesseract.image_to_string(preprocessed_image)\n",
        "    corrected_text = text.replace(\"|\", \"I\")\n",
        "    translated = GoogleTranslator(source='auto', target='iw').translate(corrected_text)\n",
        "    return translated\n",
        "\n",
        "def process_image(image, selected_option):\n",
        "    if selected_option == 'Morphological Operation':\n",
        "        return apply_morphological_operation(image)\n",
        "    elif selected_option == 'Contour Detection':\n",
        "        return detect_edge_contours(image)[0]\n",
        "    elif selected_option == 'Corner Points':\n",
        "        return find_corner_points(image)[0]\n",
        "    elif selected_option == 'Perspective Transform':\n",
        "        return apply_perspective_transform(image)\n",
        "    else:\n",
        "        return image\n",
        "\n",
        "def main():\n",
        "     # Set title and page configuration\n",
        "    st.set_page_config(page_title='Document Scanner', layout='centered', initial_sidebar_state='expanded')\n",
        "\n",
        "    # Add a title and description\n",
        "    st.title('Document Scanner')\n",
        "    st.write(\"Upload an image and select a processing technique from the dropdown menu.\")\n",
        "\n",
        "\n",
        "    uploaded_file = st.file_uploader(\"Choose a file\", type=['jpg', 'png', 'jpeg'])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        image = Image.open(uploaded_file)\n",
        "        dim_limit = 1080\n",
        "        max_dim = max(image.size)\n",
        "        if max_dim > dim_limit:\n",
        "            resize_scale = dim_limit / max_dim\n",
        "            image = image.resize((int(image.width * resize_scale), int(image.height * resize_scale)))\n",
        "\n",
        "        st.image(image, caption='Uploaded Image', use_column_width=True)\n",
        "\n",
        "        selected_option = st.selectbox('Select Image Processing Technique', [\n",
        "            'Original',\n",
        "            'Morphological Operation',\n",
        "            'Contour Detection',\n",
        "            'Corner Points',\n",
        "            'Perspective Transform'\n",
        "        ])\n",
        "\n",
        "        if selected_option != 'Original':\n",
        "            image_array = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "            processed_image = process_image(image_array, selected_option)\n",
        "            st.image(processed_image, caption=f'{selected_option} Result', use_column_width=True)\n",
        "\n",
        "        translate_button = st.button(\"Translate to Hebrew\")\n",
        "        if translate_button:\n",
        "              translated_text = perform_ocr_and_translate(image)\n",
        "              st.write(\"Translated Text:\")\n",
        "              st.write(translated_text)\n",
        "\n",
        "\n",
        "        # Add a footer\n",
        "        st.markdown(\n",
        "            \"---\\nMade with ❤️ by Elyasaf Cohen\",\n",
        "            unsafe_allow_html=True\n",
        "        )\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvj26qwLgPuN",
        "outputId": "4738cc57-2501-461a-a523-10efef171020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25h+ localtunnel@2.0.2\n",
            "updated 1 package and audited 36 packages in 0.512s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 2 \u001b[93mmoderate\u001b[0m severity vulnerabilities\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D3FfUEHhMrR",
        "outputId": "24240db5-cce1-4f28-805d-5d39acbc313f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Password/Enpoint IP for localtunnel is: 34.29.200.114\n"
          ]
        }
      ],
      "source": [
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "jRdoXc-EgTii"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhTZ3jZugkSD",
        "outputId": "9234a2ed-fe33-4fe6-e021-43f7ae9c0d58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 1.928s\n",
            "your url is: https://sad-baths-yell.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501 &"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM5X15JQp7lwX1UWrPOQWH1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}